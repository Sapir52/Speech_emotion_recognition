{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8a6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "from pylab import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "import random\n",
    "from IPython.display import Audio\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm, metrics\n",
    "import tensorflow\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,Conv1D,MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import h5py\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6243ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechEmotion():\n",
    "    def get_data(self, data_dir, name_dir):\n",
    "        ##Get list of Files in folder\n",
    "        file_name = []\n",
    "\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for filename in files:\n",
    "                file_name.append(filename)\n",
    "\n",
    "        file_name_df = pd.DataFrame(file_name, columns = ['file_name'])\n",
    "        file_name_df['encoding']= file_name_df['file_name']\n",
    "        file_name_df['ID'] = file_name_df.index \n",
    "        file_name_df['dir']= name_dir\n",
    "        return file_name_df\n",
    "    \n",
    "    def add_gender(self, encoding_df):\n",
    "        \"\"\"\n",
    "        1. Added a new column - Gender\n",
    "        2. Populated Gender column after stripping .wav from 'Actor'\n",
    "        3. Convert data type from obj to string then to int which is \n",
    "           needed to determine odd or even\n",
    "        \"\"\"\n",
    "        encoding_df['Actor'] = encoding_df['Actor'].map(lambda actor: actor.rstrip('.wav'))\n",
    "        encoding_df['Gender'] = 'Gender'\n",
    "        encoding_df['Actor'].astype(str).astype(int)\n",
    "\n",
    "        encoding_df\n",
    "        \"\"\"\n",
    "        1. Loop through each row in dataframe 'Actor' column\n",
    "        2. Set value of Gender to Female if Actor value is even or Male if odd\n",
    "        \"\"\"\n",
    "        for index, row in encoding_df.iterrows():\n",
    "            if int(row[6]) % 2 == 0:\n",
    "                row['Gender'] = '1'\n",
    "            else:\n",
    "                row['Gender'] = '0'\n",
    "        return encoding_df\n",
    "    \n",
    "    def fix_ravdass_data(self, file_name_df, flag_gender = False):\n",
    "        #Create DF seperating Values\n",
    "        # Filename identifiers\n",
    "        # Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "        # Vocal channel (01 = speech, 02 = song).\n",
    "        # Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "        # Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "        # Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "        # Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "        # Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "        \n",
    "        encoding_df = file_name_df[\"encoding\"].str.split(\"-\", n=-1, expand=True)\n",
    "        encoding_df.columns = ['Modality','Vocal_channel','Class','Intensity','Statement','Repetition','Actor']\n",
    "        \n",
    "        if flag_gender == True:\n",
    "            encoding_df = self.add_gender(encoding_df)\n",
    "        final_df = encoding_df.drop(columns=['Modality','Vocal_channel','Intensity','Statement','Repetition','Actor'])\n",
    "        #assign emotion value numbers\n",
    "        final_df.loc[final_df.Class == '01', 'Emotion'] = 'neutral'\n",
    "        final_df.loc[final_df.Class == '02', 'Emotion'] = 'calm'\n",
    "        final_df.loc[final_df.Class == '03', 'Emotion'] = 'happy'\n",
    "        final_df.loc[final_df.Class == '04', 'Emotion'] = 'sad'\n",
    "        final_df.loc[final_df.Class == '05', 'Emotion'] = 'angry'\n",
    "        final_df.loc[final_df.Class == '06', 'Emotion'] = 'fearful'\n",
    "        final_df.loc[final_df.Class == '07', 'Emotion'] = 'disgust'\n",
    "        final_df.loc[final_df.Class == '08', 'Emotion'] = 'surprise'\n",
    "\n",
    "        #merge data frame\n",
    "        pre_merged_df = file_name_df.join(final_df, how='outer')\n",
    "        merged_df = pre_merged_df.drop(columns=['encoding'])\n",
    "        merged_df.set_index('ID')\n",
    "        \n",
    "        # drop nan from dataset\n",
    "        ddf = merged_df.dropna()\n",
    "        return ddf\n",
    "    \n",
    "    def fix_toronto_data(self, t_file_name_df):\n",
    "        t_encoding_df = t_file_name_df[\"encoding\"].str.split(\"_\", n=-1, expand=True)\n",
    "        t_encoding_df.columns = ['Actor','Word','Emotion']\n",
    "        t_final_df = t_encoding_df.drop(columns=['Actor','Word'])\n",
    "        t_final_df = t_final_df['Emotion'].str.strip('.wav')\n",
    "        toronto_df = pd.DataFrame(t_final_df)\n",
    "        \n",
    "        #Fix odd values in file and convert Nuetral class to calm\n",
    "        toronto_df.loc[toronto_df.Emotion == 'ps', 'Emotion'] = 'surprise'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'ngry', 'Emotion'] = 'angry'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'fear', 'Emotion'] = 'fearful'\n",
    "        #assign emotion value numbers\n",
    "        toronto_df.loc[toronto_df.Emotion == 'neutral', 'Class'] = '01'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'calm', 'Class'] = '02'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'happy', 'Class'] = '03'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'sad', 'Class'] = '04'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'angry', 'Class'] = '05'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'fearful', 'Class'] = '06'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'disgust', 'Class'] = '07'\n",
    "        toronto_df.loc[toronto_df.Emotion == 'surprise', 'Class'] = '08'\n",
    "        \n",
    "        #merge data frame and export CSV\n",
    "        t_pre_merged_df = t_file_name_df.join(toronto_df, how='outer')\n",
    "        t_merged_df = t_pre_merged_df.drop(columns=['encoding'])\n",
    "        t_merged_df = t_merged_df[['file_name', 'dir', 'Class','Emotion','ID']]\n",
    "        t_merged_df.set_index('ID')\n",
    "        \n",
    "        ddf2 = t_merged_df.dropna()\n",
    "        return ddf2\n",
    "    \n",
    "    def conact_dataset_and_reset_index(self, ddf, ddf2):\n",
    "        dataset_df = pd.concat([ddf, ddf2])\n",
    "        dataset2 = dataset_df.reset_index(drop=True)\n",
    "        dataset2['ID']= dataset2.index\n",
    "        final_dataset_df = dataset2\n",
    "        return final_dataset_df\n",
    "    \n",
    "    def save_csv(self, path, df, index_file):\n",
    "        df.to_csv(path, index = index_file)\n",
    "     \n",
    "    def read_csv(self, path):\n",
    "        return pd.read_csv(path)\n",
    "        \n",
    "    def parser(self,row,flag_gender = False):\n",
    "       # function to load files and extract features\n",
    "       file_name = os.path.join(os.path.abspath(('data')), str(row.dir), str(row.file_name))\n",
    "       # handle exception to check if there isn't a file which is corrupted\n",
    "       try:\n",
    "          # extraction\n",
    "          X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "          # extract mfcc data\n",
    "          mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=128).T,axis=0) \n",
    "       except Exception as e:\n",
    "          print(\"Error encountered while parsing file: \", file_name)\n",
    "          return None, None, None\n",
    "    \n",
    "       feature = mfccs\n",
    "       if flag_gender == True:\n",
    "           label = row.Gender\n",
    "       else:\n",
    "           label = row.Class\n",
    "       emotion = row.Emotion\n",
    "       return [feature, label, emotion]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a39f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models():\n",
    "    def get_confusion_matrix(self, y_test_clf, y_pred_clf, exp):\n",
    "        cm = confusion_matrix(y_test_clf, y_pred_clf)\n",
    "        plt.figure(figsize = (12, 10))\n",
    "        cm = pd.DataFrame(cm , index = [i for i in exp] , columns = [i for i in exp])\n",
    "        sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "        plt.title('Confusion Matrix', size=20)\n",
    "        plt.xlabel('Predicted Labels', size=14)\n",
    "        plt.ylabel('Actual Labels', size=14)\n",
    "        plt.show()\n",
    "      \n",
    "    def convert_data_to_scaler(self, X_train, X_test, name_file):\n",
    "        X_scaler = StandardScaler().fit(X_train)\n",
    "        joblib.dump(X_scaler, name_file)\n",
    "        X_train_scaled = X_scaler.transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "        return X_train_scaled, X_test_scaled\n",
    "    \n",
    "    def random_forest_classifier(self, X_train_scaled, y_train):\n",
    "        # Create Random Forest classifer object\n",
    "        rf = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "        # Train andom Forest Classifer\n",
    "        rf = rf.fit(X_train_scaled, y_train)\n",
    "        return rf\n",
    "    \n",
    "    def decision_tree_classifier(self, X_train_scaled, y_train):\n",
    "        # Create Decision Tree classifer object\n",
    "        dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        # Train Decision Tree Classifer\n",
    "        dt = dt.fit(X_train_scaled, y_train)\n",
    "        return dt\n",
    "    \n",
    "    def knn_classifier(self, X_train_scaled, y_train):\n",
    "        # Create KNN classifer object\n",
    "        knn = KNeighborsClassifier(n_neighbors = 8)\n",
    "        # Train KNN Classifer\n",
    "        knn = knn.fit(X_train_scaled, y_train)\n",
    "        return knn\n",
    "\n",
    "    def svc_classifier(self, X_train_scaled, y_train):\n",
    "        # Create SVC classifer object\n",
    "        svc = svm.SVC(probability = True, random_state=0)\n",
    "        # Train SVM Classifer\n",
    "        svc.fit(X_train_scaled, y_train)\n",
    "        return svc\n",
    "    \n",
    "    def model_evaluation(self, clf, X_test_scaled, y_test, exp):\n",
    "        clf.score(X_test_scaled, y_test)\n",
    "        predictions = clf.predict(X_test_scaled)\n",
    "        print(\"Accuracy Classifier: {}%\".format(round(accuracy_score(y_test, predictions)*100,2)))\n",
    "        print(classification_report(y_test, predictions))\n",
    "        self.get_confusion_matrix(y_test, predictions, exp)\n",
    "        \n",
    "    def save_classifier(self, clf, name_clf):\n",
    "        joblib.dump(clf, name_clf)\n",
    "        \n",
    "        \n",
    "    def one_hot(self, y_train, y_test):\n",
    "        # As this is a multiclass classification problem onehotencoding our Y.\n",
    "        encoder = OneHotEncoder()\n",
    "        y_train_oneHot  = encoder.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "        y_test_oneHot  = encoder.fit_transform(np.array(y_test).reshape(-1,1)).toarray()\n",
    "        return encoder, y_train_oneHot, y_test_oneHot\n",
    "\n",
    "    def get_model(self, y_train_oneHot, X_train_scaled, flag_gender = False):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=256, activation='relu', input_dim=X_train_scaled.shape[1], kernel_regularizer=l2(0.05)))\n",
    "        model.add(Dense(units=256, activation='relu', kernel_regularizer=l2(0.05)))\n",
    "        model.add(Dropout(0.4))\n",
    "        if flag_gender == True:\n",
    "            model.add(Dense(units=y_train_oneHot.shape[1], activation='sigmoid'))\n",
    "        else:\n",
    "            model.add(Dense(units=y_train_oneHot.shape[1], activation='softmax'))\n",
    "        # Compile the model\n",
    "        opt =  tensorflow.keras.optimizers.RMSprop(lr=0.0001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def fit_model(self, model, X_train_scaled, y_train_oneHot, X_test_scaled,y_test_oneHot, all):\n",
    "        # Fit the model to the training data\n",
    "        history = model.fit(X_train_scaled,y_train_oneHot, epochs=140, validation_data=(X_test_scaled,y_test_oneHot),\n",
    "                            verbose=1, callbacks= all)\n",
    "        return history\n",
    "\n",
    "    def show_loss_and_accuracy(self,model, history, X_test_scaled, y_test_oneHot):\n",
    "        print(\"Accuracy of our model on test data : \" , model.evaluate(X_test_scaled,y_test_oneHot)[1]*100 , \"%\")\n",
    "        epochs = [i for i in range(140)]\n",
    "        fig , ax = plt.subplots(1,2)\n",
    "        train_acc = history['accuracy']\n",
    "        train_loss = history['loss']\n",
    "        test_acc = history['val_accuracy']\n",
    "        test_loss = history['val_loss']\n",
    "\n",
    "        fig.set_size_inches(20,6)\n",
    "        ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "        ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "        ax[0].set_title('Training & Testing Loss')\n",
    "        ax[0].legend()\n",
    "        ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "        ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "        ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "        ax[1].set_title('Training & Testing Accuracy')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_xlabel(\"Epochs\")\n",
    "        plt.show()\n",
    "\n",
    "    def save_model_and_history(self, model, history, name_model, name_history):\n",
    "        model.save(name_model)\n",
    "        np.save(name_history,history.history)\n",
    "        \n",
    "    def load_model_and_history(self, name_model, name_history):\n",
    "        model = load_model(name_model)\n",
    "        history=np.load(name_history,allow_pickle='TRUE').item()\n",
    "        return model, history \n",
    "    \n",
    "    def test_predict(self,model, encoder, X_test_scaled, y_test_oneHot):\n",
    "        # predicting on test data.\n",
    "        pred_test = model.predict(X_test_scaled)\n",
    "        y_pred = encoder.inverse_transform(pred_test)\n",
    "        y_test = encoder.inverse_transform(y_test_oneHot)\n",
    "        df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "        df['Predicted Labels'] = y_pred.flatten()\n",
    "        df['Actual Labels'] = y_test.flatten()\n",
    "        return df, y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c8a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1(Callback):\n",
    "\n",
    "    def __init__(self,x_train, y_train,x_test, y_test):\n",
    "        self.x = x_train\n",
    "        self.y = y_train\n",
    "        self.x_val = x_test\n",
    "        self.y_val = y_test\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        val_predict = (np.asarray(self.model.predict(self.x_val))).round()\n",
    "        val_targ = self.y_val\n",
    "        _val_f1 = round(f1_score(val_targ, val_predict, average= 'micro'), 4)\n",
    "        print('f1_score:{}'.format(_val_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c1b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
